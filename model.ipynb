{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-10T17:46:32.839976Z",
     "iopub.status.busy": "2025-09-10T17:46:32.839613Z",
     "iopub.status.idle": "2025-09-10T17:46:32.844624Z",
     "shell.execute_reply": "2025-09-10T17:46:32.843722Z",
     "shell.execute_reply.started": "2025-09-10T17:46:32.839952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:34:25.548046Z",
     "iopub.status.busy": "2025-09-10T17:34:25.547840Z",
     "iopub.status.idle": "2025-09-10T17:34:25.565444Z",
     "shell.execute_reply": "2025-09-10T17:34:25.564728Z",
     "shell.execute_reply.started": "2025-09-10T17:34:25.548031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to use: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1  \n",
    "print(f\"Device set to use: {'cuda:0' if device==0 else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:34:25.599402Z",
     "iopub.status.busy": "2025-09-10T17:34:25.598927Z",
     "iopub.status.idle": "2025-09-10T17:34:27.188952Z",
     "shell.execute_reply": "2025-09-10T17:34:27.188057Z",
     "shell.execute_reply.started": "2025-09-10T17:34:25.599384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"vennify/t5-base-grammar-correction\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:34:27.190599Z",
     "iopub.status.busy": "2025-09-10T17:34:27.190320Z",
     "iopub.status.idle": "2025-09-10T17:34:27.216668Z",
     "shell.execute_reply": "2025-09-10T17:34:27.215988Z",
     "shell.execute_reply.started": "2025-09-10T17:34:27.190576Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ungrammatical Statement</th>\n",
       "      <th>Standard English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I goes to the store everyday.</td>\n",
       "      <td>I go to the store everyday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They was playing soccer last night.</td>\n",
       "      <td>They were playing soccer last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She have completed her homework.</td>\n",
       "      <td>She has completed her homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He don't know the answer.</td>\n",
       "      <td>He doesn't know the answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The sun rise in the east.</td>\n",
       "      <td>The sun rises in the east.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ungrammatical Statement                      Standard English\n",
       "0        I goes to the store everyday.           I go to the store everyday.\n",
       "1  They was playing soccer last night.  They were playing soccer last night.\n",
       "2     She have completed her homework.       She has completed her homework.\n",
       "3            He don't know the answer.           He doesn't know the answer.\n",
       "4            The sun rise in the east.            The sun rises in the east."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/kaggle/input/grammar-correction/Grammar Correction.csv')\n",
    "df.drop(columns={'Serial Number','Error Type'},inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:34:27.217932Z",
     "iopub.status.busy": "2025-09-10T17:34:27.217676Z",
     "iopub.status.idle": "2025-09-10T17:34:27.221501Z",
     "shell.execute_reply": "2025-09-10T17:34:27.220748Z",
     "shell.execute_reply.started": "2025-09-10T17:34:27.217911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:34:27.223330Z",
     "iopub.status.busy": "2025-09-10T17:34:27.223075Z",
     "iopub.status.idle": "2025-09-10T17:34:27.541286Z",
     "shell.execute_reply": "2025-09-10T17:34:27.540508Z",
     "shell.execute_reply.started": "2025-09-10T17:34:27.223309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "corrector = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:34:27.542318Z",
     "iopub.status.busy": "2025-09-10T17:34:27.542049Z",
     "iopub.status.idle": "2025-09-10T17:34:27.714136Z",
     "shell.execute_reply": "2025-09-10T17:34:27.713368Z",
     "shell.execute_reply.started": "2025-09-10T17:34:27.542295Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:     I goes to the store everyday.\n",
      "Corrected: I go to the store everyday.\n",
      "Corrected: I go to the store everyday.\n"
     ]
    }
   ],
   "source": [
    "input_text = df['Ungrammatical Statement'].iloc[0]\n",
    "\n",
    "predicted = corrector(input_text, max_new_tokens=128)[0]['generated_text']\n",
    "\n",
    "print(\"Input:    \", input_text)\n",
    "print(\"Corrected:\", predicted)\n",
    "print(\"Corrected:\", df['Standard English'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:34:27.715250Z",
     "iopub.status.busy": "2025-09-10T17:34:27.714964Z",
     "iopub.status.idle": "2025-09-10T17:35:13.540055Z",
     "shell.execute_reply": "2025-09-10T17:35:13.539148Z",
     "shell.execute_reply.started": "2025-09-10T17:34:27.715223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "texts = df2['Ungrammatical Statement'].tolist()\n",
    "\n",
    "results = corrector(texts, max_new_tokens=64, batch_size=16)  \n",
    "preds = [r['generated_text'] for r in results]\n",
    "\n",
    "df2['predicted'] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:35:13.541178Z",
     "iopub.status.busy": "2025-09-10T17:35:13.540978Z",
     "iopub.status.idle": "2025-09-10T17:35:13.550624Z",
     "shell.execute_reply": "2025-09-10T17:35:13.550024Z",
     "shell.execute_reply.started": "2025-09-10T17:35:13.541162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ungrammatical Statement</th>\n",
       "      <th>Standard English</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I goes to the store everyday.</td>\n",
       "      <td>I go to the store everyday.</td>\n",
       "      <td>I go to the store everyday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They was playing soccer last night.</td>\n",
       "      <td>They were playing soccer last night.</td>\n",
       "      <td>They were playing soccer last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She have completed her homework.</td>\n",
       "      <td>She has completed her homework.</td>\n",
       "      <td>She has completed her homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He don't know the answer.</td>\n",
       "      <td>He doesn't know the answer.</td>\n",
       "      <td>He doesn't know the answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The sun rise in the east.</td>\n",
       "      <td>The sun rises in the east.</td>\n",
       "      <td>The sun rises in the east.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>The festival celebrates music, culture, and to...</td>\n",
       "      <td>The festival celebrates music, culture, and br...</td>\n",
       "      <td>The festival celebrates music, culture, and to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>The seminar will address topics such as career...</td>\n",
       "      <td>The seminar will address topics such as career...</td>\n",
       "      <td>The seminar will address topics such as career...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>The research examines the effects of climate c...</td>\n",
       "      <td>The research examines the effects of climate c...</td>\n",
       "      <td>The research examines the effects of climate c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>The report highlights the need for investment,...</td>\n",
       "      <td>The report highlights the need for investment,...</td>\n",
       "      <td>The report highlights the need for investment,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>The program encourages students to think creat...</td>\n",
       "      <td>The program encourages students to think creat...</td>\n",
       "      <td>The program encourages students to think creat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2018 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Ungrammatical Statement  \\\n",
       "0                         I goes to the store everyday.   \n",
       "1                   They was playing soccer last night.   \n",
       "2                      She have completed her homework.   \n",
       "3                             He don't know the answer.   \n",
       "4                             The sun rise in the east.   \n",
       "...                                                 ...   \n",
       "2013  The festival celebrates music, culture, and to...   \n",
       "2014  The seminar will address topics such as career...   \n",
       "2015  The research examines the effects of climate c...   \n",
       "2016  The report highlights the need for investment,...   \n",
       "2017  The program encourages students to think creat...   \n",
       "\n",
       "                                       Standard English  \\\n",
       "0                           I go to the store everyday.   \n",
       "1                  They were playing soccer last night.   \n",
       "2                       She has completed her homework.   \n",
       "3                           He doesn't know the answer.   \n",
       "4                            The sun rises in the east.   \n",
       "...                                                 ...   \n",
       "2013  The festival celebrates music, culture, and br...   \n",
       "2014  The seminar will address topics such as career...   \n",
       "2015  The research examines the effects of climate c...   \n",
       "2016  The report highlights the need for investment,...   \n",
       "2017  The program encourages students to think creat...   \n",
       "\n",
       "                                              predicted  \n",
       "0                           I go to the store everyday.  \n",
       "1                  They were playing soccer last night.  \n",
       "2                       She has completed her homework.  \n",
       "3                           He doesn't know the answer.  \n",
       "4                            The sun rises in the east.  \n",
       "...                                                 ...  \n",
       "2013  The festival celebrates music, culture, and to...  \n",
       "2014  The seminar will address topics such as career...  \n",
       "2015  The research examines the effects of climate c...  \n",
       "2016  The report highlights the need for investment,...  \n",
       "2017  The program encourages students to think creat...  \n",
       "\n",
       "[2018 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:42:11.905893Z",
     "iopub.status.busy": "2025-09-10T17:42:11.905564Z",
     "iopub.status.idle": "2025-09-10T17:42:12.849915Z",
     "shell.execute_reply": "2025-09-10T17:42:12.848939Z",
     "shell.execute_reply.started": "2025-09-10T17:42:11.905869Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score (pre-finetuning): 0.7062136835289252\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "y_true = df2['Standard English'].tolist()\n",
    "y_pred = df2['predicted'].tolist()\n",
    "\n",
    "references = [[ref] for ref in y_true]\n",
    "\n",
    "bleu_score = bleu_metric.compute(predictions=y_pred, references=references)\n",
    "print(\"BLEU Score (pre-finetuning):\", bleu_score[\"bleu\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:46:45.613207Z",
     "iopub.status.busy": "2025-09-10T17:46:45.612625Z",
     "iopub.status.idle": "2025-09-10T17:46:45.619838Z",
     "shell.execute_reply": "2025-09-10T17:46:45.618871Z",
     "shell.execute_reply.started": "2025-09-10T17:46:45.613180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def precision_recall_fbeta(y_true: List[List[str]], y_pred: List[List[str]], beta: float = 0.5):\n",
    "    \n",
    "    assert len(y_true) == len(y_pred), \"Predictions and references must have the same length\"\n",
    "    \n",
    "    total_correct, total_pred, total_true = 0, 0, 0\n",
    "    \n",
    "    for ref, pred in zip(y_true, y_pred):\n",
    "        ref_set, pred_set = set(ref), set(pred)\n",
    "        \n",
    "        correct = len(ref_set & pred_set)\n",
    "        total_correct += correct\n",
    "        total_pred += len(pred_set)\n",
    "        total_true += len(ref_set)\n",
    "    \n",
    "    precision = total_correct / total_pred if total_pred > 0 else 0\n",
    "    recall = total_correct / total_true if total_true > 0 else 0\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        fbeta = 0\n",
    "    else:\n",
    "        fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "    \n",
    "    return precision, recall, fbeta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:46:47.021870Z",
     "iopub.status.busy": "2025-09-10T17:46:47.021006Z",
     "iopub.status.idle": "2025-09-10T17:46:47.037958Z",
     "shell.execute_reply": "2025-09-10T17:46:47.037124Z",
     "shell.execute_reply.started": "2025-09-10T17:46:47.021832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9681\n",
      "Recall: 0.9681\n",
      "F0.5 Score: 0.9681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "precision, recall, f0_5 = precision_recall_fbeta(df2['Standard English'], df2['predicted'], beta=0.5)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F0.5 Score: {f0_5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:42:50.531442Z",
     "iopub.status.busy": "2025-09-10T17:42:50.530665Z",
     "iopub.status.idle": "2025-09-10T17:42:50.577325Z",
     "shell.execute_reply": "2025-09-10T17:42:50.576582Z",
     "shell.execute_reply.started": "2025-09-10T17:42:50.531408Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Normalized Edit Distance: 0.15826667032936773\n"
     ]
    }
   ],
   "source": [
    "df2['NormalizedEditDistance'] = df2.apply(\n",
    "    lambda row: Levenshtein.distance(row['Standard English'], row['predicted']) / max(len(row['Standard English']), 1),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "average_normalized = df2['NormalizedEditDistance'].mean()\n",
    "print(\"Average Normalized Edit Distance:\", average_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T17:46:59.422391Z",
     "iopub.status.busy": "2025-09-10T17:46:59.421610Z",
     "iopub.status.idle": "2025-09-10T17:48:17.463936Z",
     "shell.execute_reply": "2025-09-10T17:48:17.463109Z",
     "shell.execute_reply.started": "2025-09-10T17:46:59.422366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Entropy Loss: 0.40006999447627956\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for idx, row in df2.iterrows():\n",
    "    inputs = tokenizer(row['Ungrammatical Statement'], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    labels = tokenizer(row['Standard English'], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    # Important: set labels input_ids\n",
    "    labels_input_ids = labels[\"input_ids\"]\n",
    "    \n",
    "    outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], labels=labels_input_ids)\n",
    "    loss = outputs.loss.item()\n",
    "    losses.append(loss)\n",
    "\n",
    "average_loss = sum(losses) / len(losses)\n",
    "print(\"Average Cross-Entropy Loss:\", average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4190066,
     "sourceId": 7235673,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
